{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'start-up.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dd8837be8112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start-up.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'start-up.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('start-up.csv',index_col=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1,X1=dmatrices('''status ~ category_code  + CA + NY + MA + TX + WA + founded_month \n",
    "                + first_funding_dayinop + ave_inf_y \n",
    "                + ag_funded_daysop + ag_raised_amount_usd_adj\n",
    "                + cr_funded_daysop + cr_raised_amount_usd_adj''',data=df,return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X1.drop(columns='Intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1['status[acquired]'].sum()/len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ac=y1['status[acquired]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##logistc regression and auc estimates\n",
    "\n",
    "X1_train,X1_test, y1_ac_train, y1_ac_test = train_test_split(X1,y1_ac,test_size=0.2, random_state=42)\n",
    "\n",
    "tuned_parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty':['l1','l2'] }\n",
    "\n",
    "log_ac = GridSearchCV(LogisticRegression(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "    \n",
    "log_ac.fit(X1_train,y1_ac_train)\n",
    "y_score=log_ac.predict_proba(X1_test)[:,1]\n",
    "\n",
    "fpr1_ac, tpr1_ac,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc1_ac = auc(fpr1_ac, tpr1_ac)\n",
    "\n",
    "y_score1=log_ac.predict_proba(X1_train)[:,1]\n",
    "\n",
    "fpr1_ac_train, tpr1_ac_train,_ = roc_curve(y1_ac_train, y_score1)\n",
    "roc_auc1_ac_train = auc(fpr1_ac_train, tpr1_ac_train)\n",
    "\n",
    "print(roc_auc1_ac,roc_auc1_ac_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1['status[ipo]'].sum()/len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ipo=y1['status[ipo]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression or ipo category\n",
    "X1_train,X1_test, y1_ipo_train, y1_ipo_test = train_test_split(X1,y1_ipo,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tuned_parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty':['l1','l2'] }\n",
    "\n",
    "log_ipo = GridSearchCV(LogisticRegression(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "\n",
    "log_ipo.fit(X1_train,y1_ipo_train)\n",
    "y_score=log_ipo.predict_proba(X1_test)[:,1]\n",
    "\n",
    "fpr1_ipo, tpr1_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc1_ipo = auc(fpr1_ipo, tpr1_ipo)\n",
    "\n",
    "y_score=log_ipo.predict_proba(X1_train)[:,1]\n",
    "\n",
    "fpr1_ipo_train, tpr1_ipo_train,_ = roc_curve(y1_ipo_train, y_score)\n",
    "roc_auc1_ipo_train = auc(fpr1_ipo_train, tpr1_ipo_train)\n",
    "\n",
    "print(roc_auc1_ipo,roc_auc1_ipo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression with normallized variables and calculating AUC\n",
    "\n",
    "# log_ac_p=pipeline.Pipeline([\n",
    "#     ('standardscaler',preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "#     ( 'log', LogisticRegression())\n",
    "# ])\n",
    "\n",
    "norm=preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X1_train_n=norm.fit_transform(X1_train)\n",
    "\n",
    "X1_test_n = norm.transform(X1_test)\n",
    "\n",
    "tuned_parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty':['l1','l2'] }\n",
    "\n",
    "\n",
    "log_ac_n=GridSearchCV(LogisticRegression(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "\n",
    "log_ac_n.fit(X1_train_n,y1_ac_train)\n",
    "y_score=log_ac_n.predict_proba(X1_test_n)[:,1]\n",
    "\n",
    "fpr1_ac_n, tpr1_ac_n,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc1_ac_n = auc(fpr1_ac, tpr1_ac)\n",
    "\n",
    "y_score=log_ac_n.predict_proba(X1_train_n)[:,1]\n",
    "\n",
    "fpr1_ac_n_train, tpr1_ac_n_train,_ = roc_curve(y1_ac_train, y_score)\n",
    "roc_auc1_ac_n_train = auc(fpr1_ac_train, tpr1_ac_train)\n",
    "\n",
    "print(roc_auc1_ac, roc_auc1_ac_n_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression with normallized variables and calculating AUC\n",
    "\n",
    "log_ipo_n=GridSearchCV(LogisticRegression(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "\n",
    "log_ipo_n.fit(X1_train_n,y1_ipo_train)\n",
    "y_score=log_ipo_n.predict_proba(X1_test_n)[:,1]\n",
    "\n",
    "fpr1_ipo_n, tpr1_ipo_n,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc1_ipo_n = auc(fpr1_ipo_n, tpr1_ipo_n)\n",
    "\n",
    "y_score=log_ipo_n.predict_proba(X1_train_n)[:,1]\n",
    "\n",
    "fpr1_ipo_n_train, tpr1_ipo_n_train,_ = roc_curve(y1_ipo_train, y_score)\n",
    "roc_auc1_ipo_n_train = auc(fpr1_ipo_n_train, tpr1_ipo_n_train)\n",
    "\n",
    "print(roc_auc1_ipo_n, roc_auc1_ipo_n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model for AC\n",
    "tuned_parameters= { \n",
    "    'n_estimators': [200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [1,2,4,5],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "randomforest_ac =  GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "randomforest_ac.fit(X1_train,y1_ac_train)\n",
    "y_score=randomforest_ac.predict_proba(X1_test)[:,1]\n",
    "\n",
    "fpr2_ac, tpr2_ac,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc2_ac = auc(fpr2_ac, tpr2_ac)\n",
    "\n",
    "\n",
    "y_score=randomforest_ac.predict_proba(X1_train)[:,1]\n",
    "\n",
    "fpr2_ac_train, tpr2_ac_train,_ = roc_curve(y1_ac_train, y_score)\n",
    "roc_auc2_ac_train = auc(fpr2_ac_train, tpr2_ac_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc2_ac, roc_auc2_ac_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model for IPO\n",
    "\n",
    "tuned_parameters= { \n",
    "    'n_estimators': [200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [1,2,4,5],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "randomforest_ipo = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring='roc_auc', cv=3, refit=True)\n",
    "randomforest_ipo.fit(X1_train,y1_ipo_train)\n",
    "\n",
    "y_score=randomforest_ipo.predict_proba(X1_test)[:,1]\n",
    "fpr2_ipo, tpr2_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc2_ipo = auc(fpr2_ipo, tpr2_ipo)\n",
    "\n",
    "y_score_train=randomforest_ipo.predict_proba(X1_train)[:,1]\n",
    "fpr2_ipo_train, tpr2_ipo_train,_ = roc_curve(y1_ipo_train, y_score_train)\n",
    "roc_auc2_ipo_train = auc(fpr2_ipo_train, tpr2_ipo_train)\n",
    "    \n",
    "\n",
    "roc_auc2_ipo, roc_auc2_ipo_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier on ipo\n",
    "learning_rates = np.logspace(-4, -0.5, 30)\n",
    "max_features= range(1,5)\n",
    "tuned_parameters = [{'learning_rate': learning_rates, 'max_features':max_features,'n_estimators':[300] }]\n",
    "n_folds = 3\n",
    "\n",
    "\n",
    "GBC_ipo=GridSearchCV(GradientBoostingClassifier(), tuned_parameters, scoring='roc_auc', cv=n_folds, refit=True)\n",
    "\n",
    "\n",
    "GBC_ipo.fit(X1_train,y1_ipo_train)\n",
    "\n",
    "y_score=GBC_ipo.predict_proba(X1_test)[:,1]\n",
    "fpr3_ipo, tpr3_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc3_ipo = auc(fpr3_ipo, tpr3_ipo)\n",
    "\n",
    "y_score_train=GBC_ipo.predict_proba(X1_train)[:,1]\n",
    "fpr3_ipo_train, tpr3_ipo_train,_ = roc_curve(y1_ipo_train, y_score_train)\n",
    "roc_auc3_ipo_train = auc(fpr3_ipo_train, tpr3_ipo_train)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc3_ipo, roc_auc3_ipo_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier on AC\n",
    "\n",
    "learning_rates = np.logspace(-4, -0.5, 30)\n",
    "max_features= range(1,5)\n",
    "tuned_parameters = [{'learning_rate': learning_rates, 'max_features':max_features,'n_estimators':[300] }]\n",
    "n_folds = 3\n",
    "\n",
    "\n",
    "GBC_ac=GridSearchCV(GradientBoostingClassifier(), tuned_parameters, scoring='roc_auc', cv=n_folds, refit=True)\n",
    "\n",
    "\n",
    "GBC_ac.fit(X1_train,y1_ac_train)\n",
    "\n",
    "y_score=GBC_ac.predict_proba(X1_test)[:,1]\n",
    "fpr3_ac, tpr3_ac,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc3_ac = auc(fpr3_ac, tpr3_ac)\n",
    "\n",
    "y_score_train=GBC_ac.predict_proba(X1_train)[:,1]\n",
    "fpr3_ac_train, tpr3_ac_train,_ = roc_curve(y1_ac_train, y_score_train)\n",
    "roc_auc3_ac_train = auc(fpr3_ac_train, tpr3_ac_train)\n",
    "\n",
    "roc_auc3_ac, roc_auc3_ac_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine on IPO\n",
    "\n",
    "tuned_parameters = [\n",
    "  {'C': [1, 10, 50], 'kernel': ['linear'],'probability':[True]},\n",
    "  {'C': [1, 10, 50], 'gamma': [0.001, 0.0001,0.01], 'kernel': ['rbf'],'probability':[True]},\n",
    " ]\n",
    "\n",
    "\n",
    "SVC1_ipo=GridSearchCV(SVC(), tuned_parameters, scoring='roc_auc', cv=n_folds, refit=True)\n",
    "\n",
    "SVC1_ipo.fit(X1_train_n,y1_ipo_train)\n",
    "\n",
    "y_score=SVC1_ipo.predict_proba(X1_test_n)[:,1]\n",
    "fpr4_ipo, tpr4_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc4_ipo = auc(fpr4_ipo, tpr4_ipo)\n",
    "\n",
    "y_score=SVC1_ipo.predict_proba(X1_train_n)[:,1]\n",
    "fpr4_ipo_train, tpr4_ipo_train,_ = roc_curve(y1_ipo_train, y_score)\n",
    "roc_auc4_ipo_train = auc(fpr4_ipo_train, tpr4_ipo_train)\n",
    "\n",
    "roc_auc4_ipo, roc_auc4_ipo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine on ac\n",
    "\n",
    "tuned_parameters = [\n",
    "  {'C': [1, 10, 50], 'kernel': ['linear'],'probability':[True]},\n",
    "  {'C': [1, 10, 50], 'gamma': [0.001, 0.0001,0.01], 'kernel': ['rbf'],'probability':[True]},\n",
    " ]\n",
    "\n",
    "SVC1_ac=GridSearchCV(SVC(), tuned_parameters, scoring='roc_auc', cv=n_folds, refit=True)\n",
    "\n",
    "SVC1_ac.fit(X1_train_n,y1_ac_train)\n",
    "\n",
    "y_score=SVC1_ac.predict_proba(X1_test_n)[:,1]\n",
    "fpr4_ac, tpr4_ac,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc4_ac = auc(fpr4_ac, tpr4_ac)\n",
    "\n",
    "y_score=SVC1_ac.predict_proba(X1_train_n)[:,1]\n",
    "fpr4_ac_train, tpr4_ac_train,_ = roc_curve(y1_ac_train, y_score)\n",
    "roc_auc4_ac_train = auc(fpr4_ac_train, tpr4_ac_train)\n",
    "\n",
    "roc_auc4_ac, roc_auc4_ac_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive-Bayes on IPO, it does not have hyperparameters \n",
    "bayes_ipo = naive_bayes.GaussianNB() # The likelihood of the features is assumed to be Gaussian\n",
    "\n",
    "bayes_ipo.fit(X1_train,y1_ipo_train)\n",
    "\n",
    "y_score=bayes_ipo.predict_proba(X1_test)[:,1]\n",
    "fpr6_ipo, tpr6_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "roc_auc6_ipo = auc(fpr6_ipo, tpr6_ipo)\n",
    "\n",
    "y_score=bayes_ipo.predict_proba(X1_train)[:,1]\n",
    "fpr6_ipo_train, tpr6_ipo_train,_ = roc_curve(y1_ipo_train, y_score)\n",
    "roc_auc6_ipo_train = auc(fpr6_ipo_train, tpr6_ipo_train)\n",
    "\n",
    "roc_auc6_ipo, roc_auc6_ipo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive-Bayes on ac, it does not have hyperparameters \n",
    "bayes_ac = naive_bayes.GaussianNB() # The likelihood of the features is assumed to be Gaussian\n",
    "\n",
    "bayes_ac.fit(X1_train,y1_ac_train)\n",
    "\n",
    "y_score=bayes_ac.predict_proba(X1_test)[:,1]\n",
    "fpr6_ac, tpr6_ac,_ = roc_curve(y1_ac_test, y_score)\n",
    "roc_auc6_ac = auc(fpr6_ac, tpr6_ac)\n",
    "\n",
    "y_score=bayes_ac.predict_proba(X1_train)[:,1]\n",
    "fpr6_ac_train, tpr6_ac_train,_ = roc_curve(y1_ac_train, y_score)\n",
    "roc_auc6_ac_train = auc(fpr6_ac_train, tpr6_ac_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_Bayes(X1, y1_ipo):\n",
    "    X1_train,X1_test, y1_ipo_train, y1_ipo_test = train_test_split(X1,y1_ipo,test_size=0.2)\n",
    "    \n",
    "    bayes = naive_bayes.GaussianNB() # The likelihood of the features is assumed to be Gaussian\n",
    "   \n",
    "    bayes.fit(X1_train,y1_ipo_train)\n",
    "\n",
    "    y_score=bayes.predict_proba(X1_test)[:,1]\n",
    "    fpr2_ipo, tpr2_ipo,_ = roc_curve(y1_ipo_test, y_score)\n",
    "    roc_auc2_ipo = auc(fpr2_ipo, tpr2_ipo)\n",
    "\n",
    "    y_score_train=bayes.predict_proba(X1_train)[:,1]\n",
    "    fpr2_ipo_train, tpr2_ipo_train,_ = roc_curve(y1_ipo_train, y_score_train)\n",
    "    roc_auc2_ipo_train = auc(fpr2_ipo_train, tpr2_ipo_train)\n",
    "\n",
    "    \n",
    "    return roc_auc2_ipo,roc_auc2_ipo_train,bayes,X1_train,X1_test, y1_ipo_train, y1_ipo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes_afew_times(X1, y1_ipo, n=10):\n",
    "    info= (pd.DataFrame([cv_Bayes(X1, y1_ipo) for j in range(n)],\n",
    "                         columns=['Test auc','Train auc', 'Model', 'X1_train','X1_test','y1_train', 'y1_test']))\n",
    "    \n",
    "#         (pd.DataFrame([mod_SVC(X1, y1_ipo) for j in range(n)],\n",
    "#                          columns=['Test auc','Train auc'])).mean()\n",
    "                         \n",
    "                         \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_b_ipo=Bayes_afew_times(X1, y1_ipo,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(info_b_ipo['Train auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(info_b_ipo['Test auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_b_ac=Bayes_afew_times(X1, y1_ac,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_b_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(info_b_ac['Train auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(info_b_ac['Test auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize= [10,10])\n",
    "# Plotting our Baseline..\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr1_ac_n,tpr1_ac_n,label='Logistic Regression', color='royalblue')\n",
    "#plt.plot(fpr1_ac,tpr1_ac,label='logr_ac')\n",
    "plt.plot(fpr2_ac,tpr2_ac,label='RandomForest')\n",
    "plt.plot(fpr3_ac,tpr3_ac,label='GradiantBoosting')\n",
    "plt.plot(fpr4_ac,tpr4_ac,label='SVM')\n",
    "plt.plot(fpr6_ac,tpr6_ac,label='Naive Bayes')\n",
    "plt.xlabel('FPR', size = 15)\n",
    "plt.ylabel('TPR', size = 15,rotation = 0,labelpad = 35)\n",
    "plt.legend(loc='best',prop={'size': 12})\n",
    "plt.title(\"ROC curves for evaluated models for Acquisitions\", size = 25)\n",
    "# plt.xlabel('Coefficients', size = 15, labelpad = 15)\n",
    "# plt.ylabel('Variables        ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize= [10,10])\n",
    "# Plotting our Baseline..\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr1_ipo_n,tpr1_ipo_n,label='LogisticRegression', color='royalblue')\n",
    "# plt.plot(fpr1_ipo,tpr1_ipo,label='logr_ac')\n",
    "plt.plot(fpr2_ipo,tpr2_ipo,label='RandomForest')\n",
    "plt.plot(fpr3_ipo,tpr3_ipo,label='GradiantBoosting')\n",
    "plt.plot(fpr4_ipo,tpr4_ipo,label='SVM')\n",
    "plt.plot(fpr6_ipo,tpr6_ipo,label='Naive Bayes')\n",
    "plt.xlabel('FPR', size = 15)\n",
    "plt.ylabel('TPR', size = 15,rotation = 0,labelpad = 35)\n",
    "plt.legend(loc='best',prop={'size': 12})\n",
    "plt.title(\"ROC curves for evaluated models for IPOs\", size = 25)\n",
    "# plt.xlabel('Coefficients', size = 15, labelpad = 15)\n",
    "# plt.ylabel('Variables        ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=['logr', 'logr_n','RandomForest', 'GradiantBoosting','SVM','N Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_ac=[log_ac,log_ac_n,randomforest_ac,GBC_ac,SVC1_ac,bayes_ac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_ipo=[log_ipo,log_ipo_n,randomforest_ipo,GBC_ipo,SVC1_ipo,bayes_ipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test_ac=[roc_auc1_ac,roc_auc1_ac_n, roc_auc2_ac,roc_auc3_ac,roc_auc4_ac, roc_auc6_ac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train_ac=[roc_auc1_ac_train, roc_auc1_ac_n_train, roc_auc2_ac_train,roc_auc3_ac_train,roc_auc4_ac_train, roc_auc6_ac_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test_ipo=[roc_auc1_ipo,roc_auc1_ipo_n, roc_auc2_ipo,roc_auc3_ipo,roc_auc4_ipo, roc_auc6_ipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train_ipo=[roc_auc1_ipo_train,roc_auc1_ipo_n_train, roc_auc2_ipo_train,roc_auc3_ipo_train,roc_auc4_ipo_train, roc_auc6_ipo_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ipo =[fpr1_ipo,fpr1_ipo_n,fpr2_ipo,fpr3_ipo,fpr4_ipo,fpr6_ipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ac =[fpr1_ac,fpr1_ac_n,fpr2_ac,fpr3_ac,fpr4_ac,fpr6_ac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_ac =[tpr1_ac,tpr1_ac_n,tpr2_ac,tpr3_ac,tpr4_ac,tpr6_ac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_ipo =[tpr1_ipo,tpr1_ipo_n,tpr2_ipo,tpr3_ipo,tpr4_ipo,tpr6_ipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ipo_train =[fpr1_ipo_train,fpr1_ipo_n_train,fpr2_ipo_train,fpr3_ipo_train,fpr4_ipo_train,fpr6_ipo_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ac_train =[fpr1_ac_train,fpr1_ac_n_train,fpr2_ac_train,fpr3_ac_train,fpr4_ac_train,fpr6_ac_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_ipo_train =[tpr1_ipo_train,tpr1_ipo_n_train,tpr2_ipo_train,tpr3_ipo_train,tpr4_ipo_train,tpr6_ipo_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_ac_train =[tpr1_ac_train,tpr1_ac_n_train,tpr2_ac_train,tpr3_ac_train,tpr4_ac_train,tpr6_ac_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ac=pd.DataFrame({'name':Name, 'model':Model_ac,'auc_test_ac':auc_test_ac,\n",
    "                            'auc_train_ac':auc_train_ac })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ipo=pd.DataFrame({'name':Name, 'model':Model_ipo,'auc_test_ipo':auc_test_ipo,\n",
    "                            'auc_train_ipo':auc_train_ipo})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ac[['name','auc_test_ac','auc_train_ac']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ac_n.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_ac.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ipo_n.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score_ac_n=[]\n",
    "precision_score_ac_n=[]\n",
    "f1_score_ac=[]\n",
    "for i in np.linspace(0,1,100):\n",
    "    y_score=log_ac_n.predict_proba(X1_test_n)[:,1]>i\n",
    "#     sklearn.metrics.recall_score(y1_ac_test, y_pred)#, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "    \n",
    "    precision_score_ac_n.append(metrics.precision_score(y1_ac_test, y_score))#, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "    recall_score_ac_n.append(metrics.recall_score(y1_ac_test, y_score))\n",
    "    f1_score_ac.append(metrics.f1_score(y1_ac_test, y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argmax(f1_score_ac)\n",
    "list(np.linspace(0,1,100))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_ac[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [10,10])\n",
    "x=np.linspace(0,1,100)\n",
    "y=recall_score_ac_n\n",
    "y2=precision_score_ac_n\n",
    "y3=f1_score_ac\n",
    "\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "plt.plot(x,y,label='AC_recall',color='gold')\n",
    "plt.plot(x,y2,label='AC_precision',color='royalblue')\n",
    "plt.plot(x,y3,label='AC_f1_score',color='tomato')\n",
    "#plt.axvline(0.215, color='gold', linestyle='solid')\n",
    "plt.title(\"Metrics vs. Threshold AC \\n\", size = 25)\n",
    "\n",
    "plt.xlabel('Threshold', size = 20, labelpad = 15)\n",
    "plt.ylabel('Metrics \\n ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "sns.despine()\n",
    "plt.legend(loc='best',prop={'size': 20});\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >0.17171717171717174\n",
    "# y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >x[np.argmax(roc_auc_ac_n)]\n",
    "\n",
    "cm_ac_logn=confusion_matrix(y1_ac_test, y_ac_predlogn)\n",
    "cm_ac_logn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_ac_test, y_ac_predlogn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argmax(precision_score_ac_n)\n",
    "list(np.linspace(0,1,100))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_ac_n[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >0.4646464646464647\n",
    "# y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >x[np.argmax(roc_auc_ac_n)]\n",
    "\n",
    "cm_ac_logn=confusion_matrix(y1_ac_test, y_ac_predlogn)\n",
    "cm_ac_logn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_ac_test, y_ac_predlogn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score_ipo_n=[]\n",
    "precision_score_ipo_n=[]\n",
    "f1_score_ipo=[]\n",
    "\n",
    "for i in np.linspace(0,1,100):\n",
    "    y_score=log_ipo_n.predict_proba(X1_test_n)[:,1]>i\n",
    "#     sklearn.metrics.recall_score(y1_ac_test, y_pred)#, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "    \n",
    "    precision_score_ipo_n.append(metrics.precision_score(y1_ipo_test, y_score))#, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "    recall_score_ipo_n.append(metrics.recall_score(y1_ipo_test, y_score))\n",
    "    f1_score_ipo.append(metrics.f1_score(y1_ipo_test, y_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [10,10])\n",
    "x=np.linspace(0,1,100)\n",
    "y=recall_score_ipo_n\n",
    "y2=precision_score_ipo_n\n",
    "y3=f1_score_ipo\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "plt.plot(x,y,label='IPO_recall',color='gold')\n",
    "plt.plot(x,y2,label='IPO_precision',color='royalblue')\n",
    "plt.plot(x,y3,label='IPO_f1_score',color='tomato')\n",
    "plt.title(\"Metrics vs. Threshold IPO \\n\", size = 25)\n",
    "plt.xlabel('Threshold', size = 20, labelpad = 15)\n",
    "plt.ylabel('Metrics \\n', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "sns.despine()\n",
    "plt.legend(loc='best',prop={'size': 20});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argmax(f1_score_ipo)\n",
    "list(np.linspace(0,1,100))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_ipo[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ipo_predlogn=log_ipo_n.predict_proba(X1_test_n)[:,1] >0.06060606060606061\n",
    "# y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >x[np.argmax(roc_auc_ac_n)]\n",
    "\n",
    "cm_ipo_logn=confusion_matrix(y1_ipo_test, y_ipo_predlogn)\n",
    "cm_ipo_logn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_ipo_test, y_ipo_predlogn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.argmax(precision_score_ipo_n)\n",
    "list(np.linspace(0,1,100))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_ipo_n[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ipo_predlogn=log_ipo_n.predict_proba(X1_test_n)[:,1] >0.3434343434343435\n",
    "# y_ac_predlogn=log_ac_n.predict_proba(X1_test_n)[:,1] >x[np.argmax(roc_auc_ac_n)]\n",
    "\n",
    "cm_ipo_logn=confusion_matrix(y1_ipo_test, y_ipo_predlogn)\n",
    "cm_ipo_logn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_ipo_test, y_ipo_predlogn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ac_n.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = X1.columns\n",
    "coefs_ac = log_ac_n.best_estimator_.coef_[0]\n",
    "coef_ac=pd.DataFrame({'names':names,'coefs_ac':coefs_ac })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ac['abscoef']=abs(coef_ac['coefs_ac'])\n",
    "\n",
    "coef_ac=coef_ac.sort_values(by='abscoef',ascending=False)\n",
    "coef_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef2_ac=coef_ac.iloc[:18]\n",
    "coef2_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [20,20])\n",
    "crange = np.arange(len(coef2_ac))\n",
    "# # print(crange.shape, coefs.shape)\n",
    "plt.barh(crange, coef2_ac['coefs_ac'],color='royalblue')\n",
    "plt.barh(crange[:3], coef2_ac['coefs_ac'][:3],color='tomato')\n",
    "plt.yticks(crange, coef2_ac['names'])\n",
    "ax = plt.gca()\n",
    "# plt.yticks(np.arange(10), [x for x,y in ticks_y])\n",
    "plt.title(\"Coefficients for contributing variables for acquisitions\", size = 25)\n",
    "plt.xlabel('Coefficients', size = 20, labelpad = 15)\n",
    "plt.ylabel('Variables        ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = X1.columns\n",
    "coefs_ipo = log_ipo_n.best_estimator_.coef_[0]\n",
    "coef_ipo=pd.DataFrame({'names':names,'coefs_ipo':coefs_ipo })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ipo['abscoef']=abs(coef['coefs_ipo'])\n",
    "\n",
    "coef_ipo=coef_ipo.sort_values(by='abscoef',ascending=False)\n",
    "coef_ipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef2_ipo=coef_ipo.iloc[:18]\n",
    "coef2_ipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [20,20])\n",
    "crange = np.arange(len(coef2_ipo))\n",
    "# # print(crange.shape, coefs.shape)\n",
    "plt.barh(crange, coef2_ipo['coefs_ipo'],color='royalblue')\n",
    "plt.barh(crange[:3], coef2_ipo['coefs_ipo'][:3],color='tomato')\n",
    "plt.yticks(crange, coef2_ipo['names'])\n",
    "ax = plt.gca()\n",
    "# plt.yticks(np.arange(10), [x for x,y in ticks_y])\n",
    "plt.title(\"Coefficients for contributing variables for IPO\", size = 25)\n",
    "plt.xlabel('Coefficients', size = 20, labelpad = 15)\n",
    "plt.ylabel('Variables        ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Model_data_ac, open(\"Model_data_ac_wo_sa.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Model_data_ipo, open(\"Model_data_ipo_wo_sa.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ac.to_csv('Model_data_ac_wo_sa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_ipo.to_csv('Model_data_ipo_wo_sa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ac_n.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=pd.merge(coef_ipo,coef_ac,how='left', on='names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=coef.sort_values(by='abscoef_y',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [20,20])\n",
    "crange = np.arange(len(coef))\n",
    "# # print(crange.shape, coefs.shape)\n",
    "plt.barh(crange, coef['coefs_ac'],color='tomato')\n",
    "plt.barh(crange, coef['coefs_ipo'],color='royalblue')\n",
    "plt.yticks(crange, coef['names'])\n",
    "ax = plt.gca()\n",
    "# plt.yticks(np.arange(10), [x for x,y in ticks_y])\n",
    "plt.title(\"Comparison of coefficients for contributing variables for IPO and acquisitions\", size = 25)\n",
    "plt.xlabel('Coefficients', size = 20, labelpad = 15)\n",
    "plt.ylabel('Variables        ', size = 20, rotation = 0, labelpad = 35)\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "ax.yaxis.set_label_coords(-0.06,0.97)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
